{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62e18c5",
   "metadata": {},
   "source": [
    "Point-wise outliers usually occur when there are potential system failures or small glitches in the time series. This kind of outlier exists on single data point in global (comparing to the data points in the whole time series) or local manner (comparing to neighboring points). Global outliers are usually obvious, the common practice to detect global outlier is to obtain the statistical values (e.g., min/max/mean/standard deviation)of the dataset and set a threshold value for detecting the anomalous points. Local outliers usually occur in certain context, data points with same value will not be identified as an outlier if it is not exhibited in the specific context. The common strategy to detect local outliers is to identify the context (via seasonality trend decomposition, auto-correlation), then apply statistical/machine learning methods (e.g., AutoRegression, IsolationForest, OneClassSVM) to detect the outliers.\n",
    "\n",
    "\n",
    "Pattern-wise outliers usually appear when there are abnormal behaviors existing in the data. Pattern outliers refer to the subsequences (consecutive points) of the time series data whose behavior is unusual comparing to other subsequences. Common practices to detect pattern outliers including discords analysis (e.g., matrix profile [6], HotSAX [7]), and subsequence clustering [4]. Discords analysis leverages a sliding window to segment time series into multiple subsequences and computes the distances (e.g., Euclidean distance) between the subsequences to find the discords in the time series data. Subsequence clustering also applies subsequence segmentation to the time series data and adopts subsequences as features for each time point, where the size of sliding window is the number of features. Then, unsupervised machine learning methods such as clustering (e.g., KMeans, PCA) or point-wise outlier detection algorithms are adopted to detect the pattern outliers.\n",
    "\n",
    "\n",
    "System-wise outliers constantly happen when one of many systems are in abnormal state where a system is defined as a multivariate time series data. The goal of detecting system outliers is to find out a system that is under abnormal state from many of the similar systems. For example, detecting an abnormal manufacturing line from a factory with multiple manufacturing lines. The common approach to detect this kind of outliers is to perform both point-wise and pattern-wise outlier detection to get the outlierness score for each time point/subsequence, then adopt ensemble techniques to generate an overall outlieness score for each system for comparison and detection.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b721f",
   "metadata": {},
   "source": [
    "### Because we have to label each id as either an anomaly or not, we will use point-wise outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.pyplot import suptitle\n",
    "import matplotlib.style as style\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from pyod.models.combination import aom, moa, average, maximization, median\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.data import evaluate_print\n",
    "import warnings\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Set some parameters to get good visuals - style to ggplot and size to 15,10\n",
    "\n",
    "pd.set_option('display.width',170, 'display.max_rows',1000, 'display.max_columns',900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8304840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"logdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[match for match in df.columns if \"Time\" in match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['_indextime'][0],unit='s').tz_localize('utc').tz_convert('Europe/Dublin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['_time'][0],unit='s').tz_localize('utc').tz_convert('Europe/Dublin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['_indextime'][0],unit='s').tz_localize('utc').tz_convert('Europe/Dublin') - pd.to_datetime(df['_time'][0],unit='s').tz_localize('utc').tz_convert('Europe/Dublin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['start_time', '_indextime', '_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['id','start_time', '_indextime', '_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['value'] = df['_indextime'] - df['_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa864b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['timestamp'] = pd.to_datetime(df1['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4039f27",
   "metadata": {},
   "source": [
    "### Sort Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b311999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862abe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8aaa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['timestamp_diff'] = df1['timestamp'].diff().apply(lambda x: x/np.timedelta64(1, 's')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c98f0e",
   "metadata": {},
   "source": [
    "Point outliers can be univariate or multivariate, depending on whether they affect one or more time-dependent variables, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,4))\n",
    "sns.countplot(df1['timestamp_diff']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a5e62",
   "metadata": {},
   "source": [
    "### Timestamps are not continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1[['id','timestamp', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"sample_data_randomcut.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6faafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45970aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "sns.lineplot(x = 'timestamp', y = 'value',data = data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b29c21",
   "metadata": {},
   "source": [
    "We can see that there is more activity in the morning. Between 9.00 and 9.15 as people start to work. Between 10:30 - 11 am there is not activity after a spike- Tea break. Also Between 12pm - 1 pm nothing much happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = data[['timestamp', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40169c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.rc('figure',figsize=(12,8))\n",
    "plt.rc('font',size=15)\n",
    "\n",
    "result = seasonal_decompose(ts_data,model='additive', period = int(len(ts_data)/2))\n",
    "fig = result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure',figsize=(12,6))\n",
    "plt.rc('font',size=15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = result.resid.index\n",
    "y = result.resid.values\n",
    "ax.plot_date(x, y, color='black',linestyle='--')\n",
    "\n",
    "ax.annotate('Anomaly', (mdates.date2num(x[35]), y[35]), xytext=(30, 20), \n",
    "           textcoords='offset points', color='red',arrowprops=dict(facecolor='red',arrowstyle='fancy'))\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7467e0a",
   "metadata": {},
   "source": [
    "#### Pros\n",
    "\n",
    "It’s simple, robust, it can handle a lot of different situations, and all anomalies can still be intuitively interpreted.\n",
    "\n",
    "#### Cons\n",
    "\n",
    "The biggest downside of this technique is rigid tweaking options. Apart from the threshold and maybe the confidence interval, there isn’t much you can do about it. For example, you’re tracking users on your website that was closed to the public and then was suddenly opened. In this case, you should track anomalies that occur before and after launch periods separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c9414",
   "metadata": {},
   "source": [
    "### PYOD\n",
    "\n",
    "* https://neptune.ai/blog/anomaly-detection-in-time-series\n",
    "* https://pyod.readthedocs.io/en/latest/\n",
    "\n",
    "Contamination is an important parameter here and I have arrived at its value based on trial and error on validating its results with outliers in 2D plot. It stands for percentage of outlier points in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.value.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f644db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.expand_dims(data['value'][:5000], axis=1)\n",
    "# X_test = np.expand_dims(data['value'][5000:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ab602",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_norm = standardizer(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "# train IForest detector\n",
    "clf_name = 'IForest'\n",
    "clf = IForest()\n",
    "clf.fit(data2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0182b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_  # raw outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'] = y_train_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "start, end = 0, len(data)\n",
    "\n",
    "data_subset = data[start:end]\n",
    "\n",
    "ax1.plot(data_subset[\"timestamp\"], data_subset[\"value\"], color=\"C0\", alpha=0.8)\n",
    "ax2.plot(data_subset[\"timestamp\"],data_subset[\"score\"], color=\"C1\")\n",
    "\n",
    "ax1.grid(which=\"major\", axis =\"both\")\n",
    "\n",
    "ax1.set_ylabel(\"Value\", color=\"C0\")\n",
    "ax2.set_ylabel(\"Anomaly Score\", color=\"C1\")\n",
    "\n",
    "ax1.tick_params(\"y\", color=\"C0\")\n",
    "ax2.tick_params(\"y\", color=\"C1\")\n",
    "\n",
    "fig.set_figwidth(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3575ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emmv import emmv_scores\n",
    "emmv_scores(clf, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f57cc9",
   "metadata": {},
   "source": [
    "### Note we have anomaly score where our eyeball-norm method suggests there is an anomalous data point as well as some places where our eyesballs are not as accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train_scores, bins='auto') \n",
    "plt.title(\"Histogram for Model Anomaly Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c5ba4",
   "metadata": {},
   "source": [
    "If we use a histogram to count the frequency by the anomaly score, we will see the high scores corresponds to a low frequency — evidence of outliers. We choose 0.01 to be the cut point and those >=0.01 to be outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f261d3d",
   "metadata": {},
   "source": [
    "## Plot any data point with scores greater than 3 standard deviations (approximately 99.9th percentile from the mean score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = data['score'].mean()\n",
    "score_std = data['score'].std()\n",
    "score_cutoff = score_mean + 3* score_std\n",
    "\n",
    "anomalies = data_subset[data_subset['score'] > score_cutoff]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155e29",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_anomaly'] = np.where(df['id'].isin(list(anomalies['id'])), 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140eaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = df[['id', 'is_anomaly']].merge(data[['id', 'y_pred']], on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accuracy_score(eval_df['is_anomaly'], eval_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(eval_df['is_anomaly'], eval_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a92b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(eval_df['is_anomaly'], eval_df['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e85b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id'] == 5416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c439b02",
   "metadata": {},
   "source": [
    "### Combination Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ce8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75becab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e94c0e3",
   "metadata": {},
   "source": [
    "\"\"\"Example of combining multiple base outlier scores. Four combination\n",
    "frameworks are demonstrated:\n",
    "1. Average: take the average of all base detectors\n",
    "2. maximization : take the maximum score across all detectors as the score\n",
    "3. Average of Maximum (AOM)\n",
    "4. Maximum of Average (MOA)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ac4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data for processing\n",
    "X_train = data.value.to_numpy().reshape(-1,1)\n",
    "X_train_norm = standardizer(X_train)\n",
    "n_clf = 2  # number of base detectors\n",
    "# Initialize 20 base detectors for combination\n",
    "iforest_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140,\n",
    "           150, 160, 170, 180, 190, 200]\n",
    "\n",
    "train_scores = np.zeros([X_train.shape[0], n_clf])\n",
    "\n",
    "for i in range(n_clf):\n",
    "    iforest = iforest_list[i]\n",
    "\n",
    "    clf =  IForest(n_estimators=iforest)\n",
    "    clf.fit(X_train_norm)\n",
    "\n",
    "    train_scores[:, i] = clf.decision_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision scores have to be normalized before combination\n",
    "train_scores_norm = standardizer(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e5b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14f7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination by average\n",
    "train_by_average = average(train_scores_norm)\n",
    "data['score_average'] = train_by_average\n",
    "score_mean = data['score_average'].mean()\n",
    "score_std = data['score_average'].std()\n",
    "score_cutoff = score_mean + 3* score_std\n",
    "\n",
    "anomalies_avg = data[data['score_average'] > score_cutoff]\n",
    "(anomalies_avg.shape[0] / df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "start, end = 0, len(data)\n",
    "\n",
    "data_subset = data[start:end]\n",
    "\n",
    "ax1.plot(data_subset[\"timestamp\"], data_subset[\"value\"], color=\"C0\", alpha=0.8)\n",
    "ax2.plot(data_subset[\"timestamp\"],data_subset[\"score_average\"], color=\"C1\")\n",
    "\n",
    "ax1.grid(which=\"major\", axis =\"both\")\n",
    "\n",
    "ax1.set_ylabel(\"Value\", color=\"C0\")\n",
    "ax2.set_ylabel(\"Anomaly Score\", color=\"C1\")\n",
    "\n",
    "ax1.tick_params(\"y\", color=\"C0\")\n",
    "ax2.tick_params(\"y\", color=\"C1\")\n",
    "\n",
    "fig.set_figwidth(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33794a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install emmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ce398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbd57f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
